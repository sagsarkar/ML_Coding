{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEgmDkiEQDDvHYYESmp50L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagsarkar/ML_Coding/blob/main/feed_forward_mnist_sgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "L2kX3HScA7NJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST\n",
        "mnist = load_digits()\n",
        "\n",
        "# Get features and labels and normalize features\n",
        "features, labels = mnist.data, mnist.target\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "\n",
        "# Get dataset parameters\n",
        "num_data_points, feature_dim = features.shape\n",
        "num_classes = len(np.unique(labels))"
      ],
      "metadata": {
        "id": "eC0KBrGmvE6_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense():\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.W = np.random.randn(output_size, input_size)\n",
        "        self.bias = np.random.randn(output_size, 1)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        return np.dot(input, self.W.T) + self.bias.T\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate=1e-3):\n",
        "        dW = np.dot(output_gradient, self.input.T)\n",
        "        db = output_gradient\n",
        "        input_gradient = np.dot(self.W.T, output_gradient)\n",
        "\n",
        "        self.W -= learning_rate * dW\n",
        "        self.bias -= learning_rate * db\n",
        "\n",
        "        return input_gradient"
      ],
      "metadata": {
        "id": "2VBbAWvFXFsc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "  def __init__(self):\n",
        "    def sigmoid(x):\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "    def sigmoid_prime(x):\n",
        "      s = sigmoid(x)\n",
        "      return s * (1 - s)\n",
        "\n",
        "    self.activation = sigmoid\n",
        "    self.activation_prime = sigmoid_prime\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    return self.activation(self.input)\n",
        "\n",
        "  def backward(self, output_gradient, learning_rate=None):\n",
        "        return np.multiply(output_gradient, self.activation_prime(self.input))"
      ],
      "metadata": {
        "id": "4C2-y9zIdfeK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftmaxWithCrossEntropy:\n",
        "  def forward(self, input):\n",
        "    tmp = np.exp(input)\n",
        "    self.output = tmp / np.sum(tmp)\n",
        "    return self.output\n",
        "\n",
        "  def backward(self, y_true):\n",
        "    input_gradient = self.output - y_true\n",
        "    return input_gradient"
      ],
      "metadata": {
        "id": "BpvJeUwOpIRw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dim1 = 32\n",
        "hidden_dim2 = 16\n",
        "output_dim = num_classes\n",
        "network = [Dense(feature_dim, hidden_dim1),\n",
        "           Sigmoid(),\n",
        "           Dense(hidden_dim1, hidden_dim2),\n",
        "           Sigmoid(),\n",
        "           Dense(hidden_dim2, output_dim)]\n",
        "\n",
        "output_layer = SoftmaxWithCrossEntropy()"
      ],
      "metadata": {
        "id": "_VxkaGcduwo9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_pred, oh_label):\n",
        "  return sum([-oh_label[i]*np.log2(y_pred[i]) for i in range(oh_label.shape[0])])"
      ],
      "metadata": {
        "id": "e_Rvo7eNEqC4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(true_classes_per_epoch, predictions_per_epoch):\n",
        "  return 100 * np.sum(np.array(predictions_per_epoch) == np.array(true_classes_per_epoch))/num_data_points"
      ],
      "metadata": {
        "id": "eZvpgvzrMH9j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.array([i for i in range(num_classes)])\n",
        "NUM_EPOCHS = 200\n",
        "for epoch_no in range(NUM_EPOCHS):\n",
        "  loss_per_epoch = []\n",
        "  predictions_per_epoch = []\n",
        "  true_classes_per_epoch = []\n",
        "  for idx in range(num_data_points):\n",
        "    input = features[idx].reshape(-1,1)\n",
        "    true_class = labels[idx]\n",
        "    oh_label = np.where(classes==true_class, 1, 0).reshape(-1,1)\n",
        "\n",
        "    x = input\n",
        "    for i, layer in enumerate(network):\n",
        "      x = layer.forward(x)\n",
        "\n",
        "    y_pred = output_layer.forward(x)\n",
        "    predicted_class = np.argmax(y_pred)\n",
        "    predictions_per_epoch.append(predicted_class)\n",
        "    true_classes_per_epoch.append(true_class)\n",
        "\n",
        "    loss = cross_entropy_loss(y_pred, oh_label)\n",
        "    loss_per_epoch.append(loss)\n",
        "\n",
        "    loss_grad = output_layer.backward(oh_label)\n",
        "    output_gradient = loss_grad\n",
        "    for layer in reversed(network):\n",
        "      output_gradient = layer.backward(output_gradient)\n",
        "\n",
        "  loss_per_epoch = np.mean(np.array(loss_per_epoch))\n",
        "  accuracy_per_epoch = get_accuracy(true_classes_per_epoch, predictions_per_epoch)\n",
        "\n",
        "  if (epoch_no+1) % 10 == 0:\n",
        "    values = {'epoch_no': epoch_no, 'loss_per_epoch': loss_per_epoch, 'accuracy_per_epoch': accuracy_per_epoch}\n",
        "    print(\"{epoch_no}: {loss_per_epoch}, {accuracy_per_epoch}\".format(**values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSEg0UIz5QSe",
        "outputId": "d1d7a125-f11f-4d3c-a17c-c2ae2f7b8040"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9: 2.233545802301231, 49.91652754590985\n",
            "19: 1.5460926933414634, 69.17084028937117\n",
            "29: 1.1838421817633955, 77.90762381747356\n",
            "39: 0.9480992686814801, 83.58375069560378\n",
            "49: 0.7828895772687312, 87.0895937673901\n",
            "59: 0.6614192295531732, 89.64941569282136\n",
            "69: 0.5693775096464049, 91.37451307735114\n",
            "79: 0.49818849693546585, 92.65442404006677\n",
            "89: 0.4418897911316802, 93.37785197551474\n",
            "99: 0.39580766125338895, 94.04563160823595\n",
            "109: 0.3570576575192365, 94.93600445186422\n",
            "119: 0.3249037596569477, 95.60378408458541\n",
            "129: 0.2980170534517782, 95.88202559821926\n",
            "139: 0.27500085078415865, 96.38286032276015\n",
            "149: 0.2549722529600767, 96.60545353366723\n",
            "159: 0.23735921795278095, 96.99499165275459\n",
            "169: 0.2217410452473486, 97.27323316638842\n",
            "179: 0.20771011151949242, 97.6627712854758\n",
            "189: 0.19498106024615916, 97.94101279910963\n",
            "199: 0.18337847173076974, 98.10795770728993\n"
          ]
        }
      ]
    }
  ]
}